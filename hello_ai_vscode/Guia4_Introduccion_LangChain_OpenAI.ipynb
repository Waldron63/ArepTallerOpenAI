{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83152e03",
   "metadata": {},
   "source": [
    "# Guía 3 — Introducción a LangChain con OpenAI API\n",
    "Curso: **IA en el Aula — Nivel Avanzado**  \n",
    "Profesor: **Luis Daniel Benavides Navarro**  \n",
    "Fecha: **Octubre 2025**\n",
    "\n",
    "En esta guía aprenderás los conceptos básicos de **LangChain**, una librería diseñada para construir aplicaciones impulsadas por modelos de lenguaje, integrando la API de OpenAI con flujos más complejos. Exploraremos cómo crear un primer **prompt chain**, administrar memoria y usar herramientas para componer respuestas inteligentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4929bd",
   "metadata": {},
   "source": [
    "## 1️⃣ Instalación y configuración inicial\n",
    "LangChain se instala como cualquier otra librería de Python. También usaremos `python-dotenv` para gestionar la clave de OpenAI. Ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca0e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (2.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (1.2.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\santiago.gualdron-r\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 879.4/879.4 kB 10.0 MB/s  0:00:00\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, tenacity, regex, pyyaml, ormsgpack, orjson, jsonpointer, charset_normalizer, requests, jsonpatch, tiktoken, requests-toolbelt, langgraph-sdk, langsmith, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   ----- ----------------------------------  3/22 [tenacity]\n",
      "   ------- --------------------------------  4/22 [regex]\n",
      "   --------- ------------------------------  5/22 [pyyaml]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ------------------ --------------------- 10/22 [requests]\n",
      "   --------------------- ------------------ 12/22 [tiktoken]\n",
      "   ----------------------- ---------------- 13/22 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 13/22 [requests-toolbelt]\n",
      "   ------------------------- -------------- 14/22 [langgraph-sdk]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ------------------------------ --------- 17/22 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 18/22 [langchain-openai]\n",
      "   -------------------------------- ------- 18/22 [langchain-openai]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   -------------------------------------- - 21/22 [langchain]\n",
      "   -------------------------------------- - 21/22 [langchain]\n",
      "   ---------------------------------------- 22/22 [langchain]\n",
      "\n",
      "Successfully installed charset_normalizer-3.4.4 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.2 langchain-core-1.0.1 langchain-openai-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 pyyaml-6.0.3 regex-2025.10.23 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee39b5",
   "metadata": {},
   "source": [
    "## 2️⃣ Cargar variables de entorno y cliente OpenAI\n",
    "Crea un archivo `.env` con tu clave de API y cárgala para poder usarla dentro de LangChain. Esto evita exponer tu clave en el código fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b3fcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2926d",
   "metadata": {},
   "source": [
    "## 3️⃣ Primer ejemplo: Prompt simple con LangChain\n",
    "LangChain utiliza **chains** (cadenas de pasos) para procesar información. Comencemos con una cadena simple que envía un mensaje al modelo y obtiene la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0769dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar su rendimiento en tareas específicas a partir de datos, sin ser programadas explícitamente para cada tarea. Utiliza algoritmos que identifican patrones y hacen predicciones basadas en la información proporcionada.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5349f8b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ChatPromptTemplate:** define la estructura del mensaje que se envía al modelo.\n",
    "- **ChatOpenAI:** la conexión real al modelo.\n",
    "- **chain** crea la cadena de componentes usando LCEL (LangChain Expression Language).\n",
    "- **StrOutputParser** convierte la salida estructurada del modelo en texto plano.\n",
    "- **chain.invoke:** ejecuta la cadena pasando los valores del prompt.\n",
    "\n",
    "Este patrón permite reutilizar prompts para distintos temas o contextos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6cd03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Aplicación Educativa: \"Aula Aumentada\"\n",
      "\n",
      "**Descripción General:**\n",
      "\"Aula Aumentada\" es una aplicación educativa que utiliza la realidad aumentada para enriquecer el aprendizaje en diversas materias, como ciencias, historia, matemáticas y arte. La aplicación permite a los estudiantes interactuar con contenido digital superpuesto en su entorno físico, facilitando un aprendizaje más dinámico y visual.\n",
      "\n",
      "**Características Principales:**\n",
      "\n",
      "1. **Exploración de Modelos 3D:**\n",
      "   - Los estudiantes pueden escanear objetos en su entorno (por ejemplo, una planta, un modelo geográfico o un artefacto histórico) para visualizar modelos 3D interactivos. Por ejemplo, al escanear un libro de biología, se puede visualizar un modelo 3D del sistema circulatorio humano que los estudiantes pueden rotar y explorar.\n",
      "\n",
      "2. **Lecciones Interactivas:**\n",
      "   - La aplicación ofrece lecciones interactivas que incluyen videos, infografías y cuestionarios. Al apuntar la cámara del dispositivo a un código QR o imagen específica, los estudiantes pueden acceder a contenido adicional que complementa la lección en clase.\n",
      "\n",
      "3. **Simulaciones y Experimentos Virtuales:**\n",
      "   - En materias como química o física, los estudiantes pueden realizar experimentos virtuales en un entorno seguro. Por ejemplo, pueden simular reacciones químicas al seleccionar diferentes elementos en su entorno y ver los resultados en tiempo real a través de la RA.\n",
      "\n",
      "4. **Recorridos Históricos:**\n",
      "   - La aplicación permite a los estudiantes realizar recorridos históricos al escanear lugares o monumentos en su localidad. Al hacerlo, pueden ver reconstrucciones históricas, escuchar relatos sobre eventos importantes y aprender sobre la evolución del lugar a lo largo del tiempo.\n",
      "\n",
      "5. **Gamificación del Aprendizaje:**\n",
      "   - Se incorporan elementos de gamificación, donde los estudiantes pueden completar desafíos y misiones en su entorno real. Por ejemplo, pueden buscar \"artefactos\" en su aula o en el patio de la escuela, resolver acertijos relacionados con el contenido de la clase y ganar puntos o recompensas.\n",
      "\n",
      "6. **Colaboración y Proyectos en Grupo:**\n",
      "   - La aplicación permite a los estudiantes trabajar en proyectos en grupo, donde pueden crear y presentar su propio contenido en RA. Por ejemplo, pueden diseñar una presentación sobre un tema específico y superponer información y modelos 3D en un espacio físico para compartir con sus compañeros.\n",
      "\n",
      "**Beneficios:**\n",
      "- **Aprendizaje Activo:** Fomenta la participación activa de los estudiantes, mejorando la retención de información.\n",
      "- **Visualización Mejorada:** Facilita la comprensión de conceptos abstractos mediante representaciones visuales.\n",
      "- **Personalización del Aprendizaje:** Los estudiantes pueden aprender a su propio ritmo, explorando contenido adicional según sus intereses.\n",
      "- **Desarrollo de Habilidades Digitales:** Los estudiantes adquieren competencias tecnológicas esenciales para el futuro.\n",
      "\n",
      "**Conclusión:**\n",
      "\"Aula Aumentada\" transforma el aprendizaje tradicional en una experiencia interactiva y envolvente, aprovechando las capacidades de la realidad aumentada para motivar y educar a los estudiantes de manera efectiva.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf949db6",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **cadena_secuencial:** permite conectar varias cadenas; la salida de una se convierte en la entrada de la siguiente.\n",
    "- En este caso, el modelo primero explica el tema y luego sugiere una aplicación educativa.\n",
    "\n",
    "Este tipo de flujo es ideal para generar contenido didáctico o ideas para proyectos en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0483d0",
   "metadata": {},
   "source": [
    "## 5️⃣ Ejemplo 3: Añadir memoria a la conversación\n",
    "LangChain incluye módulos de **memoria** para mantener contexto entre múltiples interacciones. Esto permite simular conversaciones educativas más naturales, donde el modelo recuerda temas previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d363f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! ¿En qué puedo ayudarte hoy con tu clase de informática?\n",
      "Claro, aquí tienes algunos pasos para introducir la inteligencia artificial (IA) a tus estudiantes:\n",
      "\n",
      "1. **Conceptos Básicos**:\n",
      "   - **Definición**: Explica qué es la IA y sus aplicaciones en la vida cotidiana.\n",
      "   - **Tipos de IA**: Presenta la diferencia entre IA débil (especializada) y IA fuerte (general).\n",
      "\n",
      "2. **Historia y Evolución**:\n",
      "   - Ofrece un breve resumen de la evolución de la IA, desde sus inicios hasta los avances actuales.\n",
      "\n",
      "3. **Áreas de Aplicación**:\n",
      "   - Muestra ejemplos prácticos de IA en diversas áreas: salud, transporte, finanzas, entretenimiento, etc.\n",
      "\n",
      "4. **Fundamentos Técnicos**:\n",
      "   - Introduce conceptos de machine learning, redes neuronales y procesamiento de lenguaje natural de manera básica.\n",
      "\n",
      "5. **Herramientas y Lenguajes**:\n",
      "   - Presenta herramientas y lenguajes de programación utilizados en IA, como Python, TensorFlow y scikit-learn.\n",
      "\n",
      "6. **Proyectos Prácticos**:\n",
      "   - Propón proyectos simples, como crear un chatbot básico o un modelo de predicción, para que los estudiantes apliquen lo aprendido.\n",
      "\n",
      "7. **Ética y Consideraciones**:\n",
      "   - Discute las implicaciones éticas y sociales de la IA, como la privacidad, el sesgo y el impacto en el empleo.\n",
      "\n",
      "8. **Recursos Adicionales**:\n",
      "   - Proporciona materiales de lectura, cursos en línea y herramientas interactivas para que los estudiantes profundicen.\n",
      "\n",
      "9. **Fomentar la Curiosidad**:\n",
      "   - Anima a los estudiantes a investigar y explorar aplicaciones de IA que les interesen.\n",
      "\n",
      "Recuerda adaptar el contenido según el nivel de conocimiento de tus estudiantes. ¡Buena suerte!\n",
      "Aquí tienes algunos ejemplos prácticos que puedes utilizar en clase para enseñar conceptos de inteligencia artificial:\n",
      "\n",
      "1. **Chatbots**:\n",
      "   - Crea un chatbot simple utilizando plataformas como Dialogflow o Chatbot.com. Los estudiantes pueden programar respuestas básicas y entender el procesamiento de lenguaje natural.\n",
      "\n",
      "2. **Reconocimiento de Imágenes**:\n",
      "   - Utiliza herramientas como Teachable Machine de Google para que los estudiantes creen un modelo que reconozca imágenes. Pueden entrenarlo con sus propias fotos.\n",
      "\n",
      "3. **Predicción de Datos**:\n",
      "   - Propón un proyecto donde los estudiantes utilicen conjuntos de datos (como el de Iris o Titanic) en Python con bibliotecas como scikit-learn para hacer predicciones simples.\n",
      "\n",
      "4. **Análisis de Sentimientos**:\n",
      "   - Muestra cómo se puede analizar el sentimiento de un texto (como reseñas de productos) utilizando bibliotecas de Python como NLTK o TextBlob.\n",
      "\n",
      "5. **Juegos Simples**:\n",
      "   - Implementa un juego básico, como \"Tic-Tac-Toe\", donde los estudiantes programen una IA que juegue contra un humano.\n",
      "\n",
      "6. **Sistemas de Recomendación**:\n",
      "   - Explica cómo funcionan los sistemas de recomendación (como los de Netflix o Amazon) y haz que los estudiantes creen un sistema básico utilizando datos ficticios.\n",
      "\n",
      "7. **Clasificación de Texto**:\n",
      "   - Utiliza un conjunto de datos de correos electrónicos y permite que los estudiantes construyan un modelo que clasifique correos como \"spam\" o \"no spam\".\n",
      "\n",
      "8. **Visualización de Datos**:\n",
      "   - Enseña a los estudiantes a visualizar datos utilizando bibliotecas como Matplotlib o Seaborn, y discute cómo la visualización puede ayudar a entender los resultados de los modelos de IA.\n",
      "\n",
      "9. **Simulaciones de IA**:\n",
      "   - Usa simuladores de IA como OpenAI Gym para que los estudiantes experimenten con algoritmos de aprendizaje por refuerzo en entornos virtuales.\n",
      "\n",
      "10. **Proyectos Interdisciplinarios**:\n",
      "    - Anima a los estudiantes a combinar IA con otras materias, como arte (creación de arte generativo) o música (composición musical con IA).\n",
      "\n",
      "Estos ejemplos ayudarán a los estudiantes a ver la aplicación práctica de la IA y a desarrollar habilidades técnicas. ¡Diviértete enseñando!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instalar si hace falta:\n",
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de informática.\"))\n",
    "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79423b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ConversationBufferMemory:** almacena los mensajes anteriores en la conversación.\n",
    "- **ConversationChain:** combina el modelo con la memoria.\n",
    "- Esta funcionalidad es útil para tutores inteligentes o chatbots educativos que requieren continuidad en el diálogo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba0ab9",
   "metadata": {},
   "source": [
    "## 6️⃣ Buenas prácticas con LangChain + OpenAI\n",
    "- Usa prompts **claros y estructurados**: el modelo responde mejor cuando la tarea está bien definida.\n",
    "- Controla `temperature` según la tarea: bajo (0.1–0.3) para precisión, alto (0.7–0.9) para creatividad.\n",
    "- Guarda logs o historiales si tu aplicación incluye interacción prolongada.\n",
    "- Limita la longitud de las respuestas con `max_tokens` para evitar costos o respuestas excesivas.\n",
    "- Documenta tus cadenas (`LLMChain`) para reusarlas en distintos contextos educativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a40d49",
   "metadata": {},
   "source": [
    "## ✅ Conclusión\n",
    "Has aprendido los fundamentos de LangChain: prompts, chains, memoria y flujo secuencial. Estos conceptos son la base para desarrollar asistentes educativos, tutores personalizados o sistemas de generación de contenido en el aula. En la próxima guía implementaremos un **asistente educativo con RAG (Retrieval-Augmented Generation)** usando tus propios materiales docentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
