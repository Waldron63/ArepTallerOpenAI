{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32b2a27",
   "metadata": {},
   "source": [
    "# Guía de Instalación y Práctica — Sesión 1 (Notebook)\n",
    "Curso: **IA en el Aula — Nivel Avanzado**  \n",
    "Profesor: **Luis Daniel Benavides Navarro**  \n",
    "Fecha: **22 de octubre de 2025**\n",
    "\n",
    "Este cuaderno guía a los participantes para configurar el entorno, conectarse a una API de modelos de lenguaje y realizar las primeras consultas con **parámetros clave** como `temperature`, `max_tokens`, `top_p`, etc. Se incluyen explicaciones paso a paso y ejercicios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0ddd",
   "metadata": {},
   "source": [
    "## 1) Requisitos previos\n",
    "- Python 3.10 o superior\n",
    "- Cuenta y **clave API** en un proveedor de modelos de lenguaje (ej. OpenAI)\n",
    "- Editor/entorno: VSCode, Jupyter o Colab\n",
    "- Conexión a Internet\n",
    "\n",
    "Si estás en **Colab**, puedes ejecutar el siguiente comando para instalar dependencias. En local, usa tu terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc702d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# (Opcional en local/Colab) Instalar dependencias\n",
    "%pip install --quiet openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5e55a",
   "metadata": {},
   "source": [
    "## 2) Preparar variables de entorno\n",
    "Crea un archivo `.env` en la carpeta del proyecto con:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=tu_clave_aqui\n",
    "```\n",
    "Nunca publiques tu clave. Evita subir `.env` a repositorios públicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80b7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado. Modelo listo para consultas.\n"
     ]
    }
   ],
   "source": [
    "# 3) Cargar la clave y crear el cliente\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # Lee el archivo .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Cliente inicializado. Modelo listo para consultas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00221859",
   "metadata": {},
   "source": [
    "Si está en Google Colab, debe incluir la llave en los secretos (en el menú de la izquierda), activar la variable y luego inicializar así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd38611",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3) Cargar la clave y crear el cliente en google Colab\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      6\u001b[39m client = OpenAI(api_key=userdata.get(\u001b[33m'\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCliente inicializado. Modelo listo para consultas.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# 3) Cargar la clave y crear el cliente en google Colab\n",
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "print(\"Cliente inicializado. Modelo listo para consultas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174eb5a6",
   "metadata": {},
   "source": [
    "## 4) Parámetros importantes de la API (explicación breve)\n",
    "- **`model`**: identifica el modelo a consultar (p.ej., `gpt-4o-mini`).\n",
    "- **`messages`**: lista de turnos conversacionales. Usa roles `system` (instrucciones generales), `user` (tu prompt), `assistant` (respuestas previas si las hay).\n",
    "- **`temperature`**: *aleatoriedad* de la salida. Valores bajos (0.0–0.3) hacen respuestas más deterministas; valores altos (0.7–1.0) hacen respuestas más creativas.\n",
    "- **`top_p`**: alternativa a `temperature` basada en muestreo por probabilidad acumulada; usa uno u otro (no ambos a la vez a valores lejanos) para afinar el estilo.\n",
    "- **`max_tokens`**: tope de tokens generados en la respuesta. Si es muy bajo, el texto puede cortarse.\n",
    "- **`stop`**: secuencias de corte; si aparecen, la generación se detiene.\n",
    "- **`frequency_penalty` / `presence_penalty`**: penalizaciones para reducir repeticiones y fomentar aparición de nuevos términos.\n",
    "\n",
    "**Buenas prácticas:**\n",
    "- Controlar `temperature` (0.2–0.7) según la tarea (evaluación → bajo; lluvia de ideas → medio/alto).\n",
    "- Estructurar prompts y, cuando sea útil, **pedir JSON** para facilitar la automatización.\n",
    "- Evitar incluir datos personales o sensibles en prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873e7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La inteligencia artificial en la educación se refiere al uso de tecnologías que simulan la capacidad humana de aprender y resolver problemas, con el fin de personalizar el aprendizaje y mejorar la eficiencia educativa. Estas herramientas pueden analizar el rendimiento de los estudiantes, adaptar contenidos y proporcionar retroalimentación instantánea, facilitando así un aprendizaje más individualizado y efectivo.\n"
     ]
    }
   ],
   "source": [
    "# 5) Primera consulta: respuesta libre\n",
    "prompt = \"Explica en dos frases qué es la inteligencia artificial en la educación.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7  # más creativo que 0.2, menos que 1.0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e281741",
   "metadata": {},
   "source": [
    "### Comentarios sobre `temperature`\n",
    "- A `0.0–0.2`: respuestas casi siempre iguales (útil en **rubricas** o **explicaciones estándar**).\n",
    "- A `0.5–0.8`: más variación léxica/estilística (útil en **generación de materiales** o **brainstorming**).\n",
    "- A `>0.9`: creatividad alta pero riesgo de salidas menos precisas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"operation\": \"explanation\",\n",
      "  \"input\": \"¿Qué es aprendizaje supervisado?\",\n",
      "  \"output\": \"El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir la salida correcta para nuevas entradas. Se utiliza comúnmente en tareas como clasificación y regresión.\"\n",
      "}\n",
      "\n",
      "Valid JSON → {'operation': 'explanation', 'input': '¿Qué es aprendizaje supervisado?', 'output': 'El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir la salida correcta para nuevas entradas. Se utiliza comúnmente en tareas como clasificación y regresión.'}\n"
     ]
    }
   ],
   "source": [
    "# 6) Respuesta estructurada en JSON para automatización\n",
    "import json\n",
    "\n",
    "query = \"¿Qué es aprendizaje supervisado?\"\n",
    "schema_instruction = (\n",
    "    \"Responde en formato JSON con las claves: operation, input, output. \"\n",
    "    \"operation debe ser 'explanation'; input debe repetir la pregunta; output la explicación clara y breve.\"\n",
    ")\n",
    "response_json = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": schema_instruction},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ],\n",
    "    temperature=0.3,       # más determinista para formatos estructurados\n",
    "    max_tokens=300         # suficiente para una explicación breve\n",
    ")\n",
    "text = response_json.choices[0].message.content\n",
    "print(text)\n",
    "\n",
    "# (Opcional) intentar cargar como JSON si el modelo devolvió un objeto válido\n",
    "try:\n",
    "    data = json.loads(text)\n",
    "    print(\"\\nValid JSON →\", data)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\nLa salida no es JSON válido literal. Puedes parsearla manualmente o usar validadores/funciones JSON del proveedor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a1d82",
   "metadata": {},
   "source": [
    "## 7) Ejercicios propuestos\n",
    "1. Cambia `temperature` a 0.1, 0.5 y 0.9 y compara el estilo de las respuestas.\n",
    "2. Pide que el modelo responda **siempre en JSON** usando un `system` que lo exija. Verifica si cumple.\n",
    "3. Crea un prompt de tu área (p.ej., *programación*, *arquitectura*, *matemáticas*) que devuelva un JSON con `operation`, `input`, `steps` (lista) y `output`.\n",
    "4. Limita la longitud con `max_tokens` y observa si corta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eece738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
      "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura jerárquica para tomar decisiones basadas en características de los datos. Cada nodo interno representa una prueba sobre una característica, cada rama representa el resultado de esa prueba, y cada hoja representa una clase o resultado final, permitiendo así clasificar o predecir resultados a partir de nuevas entradas.\"\n",
      "}\n",
      "\n",
      "Valid JSON → {'operation': 'explanation', 'input': '¿Qué es aprendizaje supervisado?', 'output': 'El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir la salida correcta para nuevas entradas. Se utiliza comúnmente en tareas como clasificación y regresión.'}\n"
     ]
    }
   ],
   "source": [
    "# Plantilla reutilizable para el curso\n",
    "def ask_model(prompt: str,\n",
    "              model: str = \"gpt-4o-mini\",\n",
    "              temperature: float = 0.3,\n",
    "              max_tokens: int = 400,\n",
    "              system: str | None = None):\n",
    "    messages = []\n",
    "    if system:\n",
    "        messages.append({\"role\": \"system\", \"content\": system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(ask_model(\n",
    "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
    "    temperature=0.4,\n",
    "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0471181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- temperature=0.1 ---\n",
      "Un árbol de decisión es un modelo de aprendizaje automático utilizado para la clasificación y la regresión. Su funcionamiento se basa en la representación gráfica de decisiones y sus posibles consecuencias, organizadas en forma de un árbol.\n",
      "\n",
      "1. **Estructura**:\n",
      "--- temperature=0.5 ---\n",
      "Un árbol de decisión es un modelo de aprendizaje automático utilizado para clasificación y regresión. Su funcionamiento se basa en dividir un conjunto de datos en subconjuntos más pequeños y homogéneos a través de decisiones secuenciales.\n",
      "\n",
      "El principio de funcionamiento se\n",
      "--- temperature=0.9 ---\n",
      "Un árbol de decisión es una herramienta de modelado predictivo que se utiliza en el campo de la estadística y el aprendizaje automático para tomar decisiones basadas en datos. Su funcionamiento se basa en una estructura jerárquica similar a un árbol,\n"
     ]
    }
   ],
   "source": [
    "# Punto 1 Cambia `temperature` a 0.1, 0.5 y 0.9 y compara el estilo de las respuestas.\n",
    "for t in [0.1, 0.5, 0.9]:\n",
    " response = client.chat.completions.create(\n",
    " model=\"gpt-4o-mini\",\n",
    " messages=[{\"role\": \"user\", \"content\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\"}],\n",
    " temperature=t,\n",
    " max_tokens=50\n",
    " )\n",
    " print(f\"--- temperature={t} ---\")\n",
    " print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2da76bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"Explica brevemente qué es una red neuronal convolucional.\",\n",
      "  \"respuesta\": \"Una red neuronal convolucional (CNN) es un tipo de red neuronal diseñada para procesar datos con una estructura de cuadrícula, como imágenes. Utiliza capas convolucionales que aplican filtros para detectar características locales, como bordes y texturas, a lo largo de la imagen. Estas redes son especialmente efectivas en tareas de visión por computadora, como clasificación de imágenes y detección de objetos, debido a su capacidad para aprender patrones jerárquicos y reducir la dimensionalidad de los datos.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Punto 2 Pide que el modelo responda **siempre en JSON** usando un `system` que lo exija. Verifica si cumple.\n",
    "print(ask_model(\n",
    "    \"Explica brevemente qué es una red neuronal convolucional.\",\n",
    "    system=\"Responde SIEMPRE en formato JSON con las claves: {'prompt': <texto del usuario>, 'respuesta': <tu respuesta>}\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8a912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"operation\": \"calculate_sum_of_n_natural_numbers\",\n",
      "  \"input\": {\n",
      "    \"n\": \"Número natural hasta el cual se desea calcular la suma\"\n",
      "  },\n",
      "  \"steps\": [\n",
      "    \"La suma de los primeros n números naturales se puede expresar como S = 1 + 2 + 3 + ... + n.\",\n",
      "    \"Esta suma se puede simplificar usando la fórmula matemática: S = n * (n + 1) / 2.\",\n",
      "    \"La fórmula se deduce al observar que si agrupamos los números de la siguiente manera: (1 + n), (2 + (n-1)), (3 + (n-2)), ..., se obtienen n/2 pares, cada uno sumando (n + 1).\",\n",
      "    \"Por lo tanto, el número total de pares es n/2, y cada par suma (n + 1).\",\n",
      "    \"Multiplicando el número de pares por la suma de cada par, obtenemos: S = (n/2) * (n + 1).\",\n",
      "    \"Finalmente, esta fórmula se simplifica a S = n * (n + 1) / 2.\"\n",
      "  ],\n",
      "  \"output\": {\n",
      "    \"code\": \"def suma_numeros_naturales(n):\\n    # Verificamos que n sea un número natural no negativo\\n    if n < 1:\\n        return 0  # La suma de números naturales empieza desde 1\\n    # Aplicamos la fórmula S = n * (n + 1) / 2\\n    suma = n * (n + 1) // 2  # Usamos // para la división entera\\n    return suma\",\n",
      "    \"example\": {\n",
      "      \"n\": 5,\n",
      "      \"result\": 15\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Punto 3 Crea un prompt de tu área (p.ej., *programación*, *arquitectura*, *matemáticas*) que devuelva un JSON con `operation`, `input`, `steps` (lista) y `output`.\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"format-json: Responde SIEMPRE en formato JSON con las claves: \"\n",
    "            \"'operation', 'input', 'steps' (lista) y 'output'. \"\n",
    "            \"Incluye explicaciones matemáticas y código bien comentado.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Escribe una función en Python que calcule la suma de los primeros n números naturales \"\n",
    "            \"y explica detalladamente cómo se deduce la fórmula matemática usada.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Parámetros del modelo\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=400\n",
    ")\n",
    "\n",
    "# Mostrar resultado\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
      "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura en forma de árbol para tomar decisiones basadas en características\n"
     ]
    }
   ],
   "source": [
    "# Punto 4 Limita la longitud con `max_tokens` y observa si corta; se acorta el token de 400 a 50\n",
    "\n",
    "def ask_model(prompt: str,\n",
    "              model: str = \"gpt-4o-mini\",\n",
    "              temperature: float = 0.3,\n",
    "              max_tokens: int = 50,\n",
    "              system: str | None = None):\n",
    "    messages = []\n",
    "    if system:\n",
    "        messages.append({\"role\": \"system\", \"content\": system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(ask_model(\n",
    "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
    "    temperature=0.4,\n",
    "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fef7c",
   "metadata": {},
   "source": [
    "## 9) Solución de problemas comunes\n",
    "- **`openai.AuthenticationError` / `401`**: clave inválida o no cargada; revisa tu `.env` y reinicia el kernel.\n",
    "- **`Rate limit`**: excediste el número de solicitudes por minuto; espera unos segundos y reintenta.\n",
    "- **`model_not_found`**: el modelo no existe o no tienes acceso; cambia a uno disponible en tu cuenta.\n",
    "- **Salidas no JSON**: fija `temperature=0.0–0.3`, agrega instrucciones `system` estrictas y/o usa funciones nativas de validación JSON si el proveedor las ofrece.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eab4f2",
   "metadata": {},
   "source": [
    "## 10) Próximos pasos\n",
    "En la siguiente sesión se verán **consultas avanzadas**, manejo de contexto y el punto de partida para construir un **asistente con RAG** (recuperación de conocimiento) usando materiales del curso.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
